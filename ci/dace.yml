include:
  - local: 'ci/base.yml'

.test_model_stencils:
  stage: test
  script:
    - tox -r -e run_stencil_tests -c model/ -- --backend=$BACKEND --grid=$GRID
  parallel:
    matrix:
    - BACKEND: [dace_cpu, dace_gpu]
      GRID: [simple_grid, icon_grid]
test_model_stencils_x86_64:
  extends: [.test_model_stencils, .test_template_x86_64]
test_model_stencils_aarch64:
  extends: [.test_model_stencils, .test_template_aarch64]

.test_model_datatests:
  stage: test
  script:
    - tox -r -e run_model_tests -c model/ -- --backend=$BACKEND $COMPONENT
  parallel:
    matrix:
    - COMPONENT: [atmosphere/diffusion/tests/diffusion_tests, atmosphere/dycore/tests/dycore_tests]
      BACKEND: [dace_cpu_noopt]
test_model_datatests_x86_64:
  extends: [.test_model_datatests, .test_template_x86_64]
test_model_datatests_aarch64:
  extends: [.test_model_datatests, .test_template_aarch64]

.benchmark_model_stencils:
  stage: benchmark
  script:
    # force execution of tests where validation is expected to fail, because the reason for failure is wrong numpy reference
    - tox -r -e run_benchmarks -c model/ -- --backend=$BACKEND --grid=$GRID --runxfail
  parallel:
    matrix:
    - BACKEND: [dace_cpu, dace_gpu]
      GRID: [icon_grid, icon_grid_global]
benchmark_model_stencils_x86_64:
  extends: [.benchmark_model_stencils, .test_template_x86_64]
benchmark_model_stencils_aarch64:
  extends: [.benchmark_model_stencils, .test_template_aarch64]
