include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

stages:
  - baseimage
  - image
  - build
  - test
  - benchmark

variables:
  PYVERSION_PREFIX: py310
  PYVERSION: 3.10.9

# Base image build step with SHA256 checksum for caching
.build_distributed_baseimage:
  stage: baseimage
  before_script:
    # include build arguments in hash since we use a parameterized Docker file
    - DOCKER_TAG=`echo "$(cat $DOCKERFILE) $DOCKER_BUILD_ARGS" | sha256sum | head -c 16`
    - export PERSIST_IMAGE_NAME=$CSCS_REGISTRY_PATH/public/$ARCH/base/icon4py:$DOCKER_TAG-$PYVERSION
    - echo "BASE_IMAGE_${PYVERSION_PREFIX}=$PERSIST_IMAGE_NAME" >> build.env
  artifacts:
    reports:
      dotenv: build.env
  variables:
    DOCKERFILE: ci/docker/base_mpi.Dockerfile
    # change to 'always' if you want to rebuild, even if target tag exists already (if-not-exists is the default, i.e. we could also skip the variable)
    CSCS_REBUILD_POLICY: if-not-exists


build_distributed_baseimage_aarch64:
  extends: [.container-builder-cscs-gh200, .build_distributed_baseimage]
  variables:
    DOCKER_BUILD_ARGS: '["ARCH=$ARCH", "PYVERSION=$PYVERSION"]'



.build_distributed_template:
  variables:
    DOCKERFILE: ci/docker/distributed_venv.Dockerfile
    # Unique image name based on commit SHA,
    DOCKER_BUILD_ARGS: '["PYVERSION=$PYVERSION", "BASE_IMAGE=${BASE_IMAGE_${PYVERSION_PREFIX}}", "VENV=${UV_PROJECT_ENVIRONMENT}"]'
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/public/$ARCH/icon4py/icon4py-ci:$CI_COMMIT_SHA-$UV_PROJECT_ENVIRONMENT-$PYVERSION
    #USE_MPI: "YES"

.build_distributed_cpu:
  extends: [.build_distributed_template]
  variables:
    UV_PROJECT_ENVIRONMENT: venv_dist


build_distributed_cpu:
    stage: image
    extends: [.container-builder-cscs-gh200, .build_distributed_cpu]
    needs: [build_distributed_baseimage_aarch64]

.test_template_distributed:
  timeout: 8h
  image: $CSCS_REGISTRY_PATH/public/$ARCH/icon4py/icon4py-ci:$CI_COMMIT_SHA-$UV_PROJECT_ENVIRONMENT-$PYVERSION
  extends: [ .container-runner-santis-gh200, .build_distributed_cpu]
  needs: [ build_distributed_cpu ]
  variables:
    #taken from ci/base.yml - need to figure out which ones are needed and which ones should go where
    SLURM_TIMELIMIT: '06:00:00'
    #USE_MPI: "YES"
    SLURM_JOB_NUM_NODES: 1
    SLURM_NTASKS: 1
    #VIRTUALENV_SYSTEM_SITE_PACKAGES: 1
    TEST_DATA_PATH: "/icon4py/ci/testdata"
    ICON_GRID_LOC: "${TEST_DATA_PATH}/grids/mch_ch_r04b09_dsl"
    CSCS_ADDITIONAL_MOUNTS: '["/capstor/store/cscs/userlab/d126/icon4py/ci/testdata_003:$TEST_DATA_PATH"]'
    MPI_PREFIX: "mpirun --bind-to socket -np 4"
    # Grace-Hopper gpu architecture is not enabled by default in CUDA build
    #CUDAARCHS: "90"
    # Limit test parallelism to avoid "OSError: too many open files" in the gt4py build stage.
    # Another problem, observed in test stage, is that gpu tests hang in combination with CUDA MPS,
    # when high test parallelism is used.
    #NUM_PROCESSES: 16
    #ICON4PY_NOX_UV_CUSTOM_SESSION_EXTRAS: "cuda12"


.test_distributed_aarch64:
  stage: test
  extends: [.test_template_distributed]
  before_script:
    - pwd
    - echo "working directory listing $(ls)"
    - echo "using venv ${UV_PROJECT_ENVIRONMENT}"
    - cd /icon4py
    - pwd
    - echo "icon4py listing $(ls)"
    - . ${UV_PROJECT_ENVIRONMENT}/bin/activate
    - echo "running with $(python --version)"
    - echo "using MPI_PREFIX ${MPI_PREFIX}"
  script:
      #- ${MPI_PREFIX} uv run pytest -sv -k "mpi_tests" --with-mpi --backend=$BACKEND model/$COMPONENT
      - uv run pytest -sv --datatest-only --backend=$BACKEND model/$COMPONENT
  parallel:
    matrix:
      - COMPONENT: [ atmosphere/diffusion, common] # [advection, diffusion, dycore, microphysics, common, driver]
        BACKEND: [ gtfn_cpu]
  rules:
    - when: on_success

test_model_distributed:
  extends: [.test_distributed_aarch64]

