include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

stages:
  - image
  - build
  - test
  - benchmark

variables:
  PYVERSION_PREFIX: py310
  PYVERSION: 3.10.9

  # Base image build step with SHA256 checksum for caching
.build_model_baseimage:
  stage: image
  before_script:
    # include build arguments in hash since we use a parameterized Docker file
    - DOCKER_TAG=`echo "$(cat $DOCKERFILE) $DOCKER_BUILD_ARGS" | sha256sum | head -c 16`
    - export PERSIST_IMAGE_NAME=$CSCS_REGISTRY_PATH/public/$ARCH/base/icon4py:$DOCKER_TAG-model-$PYVERSION
    - echo "BASE_IMAGE_${PYVERSION_PREFIX}=$PERSIST_IMAGE_NAME" >> build.env
  artifacts:
    reports:
      dotenv: build.env
  variables:
    DOCKERFILE: ci/docker/base_model.Dockerfile
    # change to 'always' if you want to rebuild, even if target tag exists already (if-not-exists is the default, i.e. we could also skip the variable)
    CSCS_REBUILD_POLICY: if-not-exists
    DOCKER_BUILD_ARGS: '["ARCH=$ARCH", "PYVERSION=$PYVERSION"]'

build_model_baseimage_aarch64:
  extends: [.container-builder-cscs-gh200, .build_model_baseimage]
  variables:


.build_distributed_template:
  variables:
    UV_PROJECT_ENVIRONMENT: venv_dist
    USE_MPI: "YES"

.build_distributed:
  extends: [.build_distributed_template]
  variables:
    DOCKERFILE: ci/docker/distributed_venv.Dockerfile
    # Unique image name based on commit SHA,
    DOCKER_BUILD_ARGS: '["PYVERSION=$PYVERSION", "BASE_IMAGE=${BASE_IMAGE_${PYVERSION_PREFIX}}", "VENV=${UV_PROJECT_ENVIRONMENT}"]'
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/public/$ARCH/icon4py/icon4py-ci:$CI_COMMIT_SHA-$UV_PROJECT_ENVIRONMENT-$PYVERSION


build_distributed:
    stage: build
    extends: [.container-builder-cscs-gh200, .build_distributed]
    needs: [build_model_baseimage_aarch64] #[build_baseimage_aarch64]

.test_template_distributed:
  timeout: 8h
  image: $CSCS_REGISTRY_PATH/public/$ARCH/icon4py/icon4py-ci:$CI_COMMIT_SHA-$UV_PROJECT_ENVIRONMENT-$PYVERSION
  extends: [ .container-runner-santis-gh200, .build_distributed_template ]
  needs: [ build_distributed ]
  variables:
    #taken from ci/base.yml - need to figure out which ones are needed and which ones should go where
    SLURM_TIMELIMIT: '06:00:00'
    USE_MPI: "YES"
    SLURM_JOB_NUM_NODES: 1
    SLURM_NTASKS: 4
    CRAY_CUDA_MPS: 1
    VIRTUALENV_SYSTEM_SITE_PACKAGES: 1
    TEST_DATA_PATH: "/icon4py/ci/testdata"
    ICON_GRID_LOC: "${TEST_DATA_PATH}/grids/mch_ch_r04b09_dsl"
    CUDACXX: "${HPC_SDK_PATH}/compilers/bin/nvcc"
    CSCS_ADDITIONAL_MOUNTS: '["/capstor/store/cscs/userlab/d126/icon4py/ci/testdata_002:$TEST_DATA_PATH"]'
    # Grace-Hopper gpu architecture is not enabled by default in CUDA build
    CUDAARCHS: "90"
    # Limit test parallelism to avoid "OSError: too many open files" in the gt4py build stage.
    # Another problem, observed in test stage, is that gpu tests hang in combination with CUDA MPS,
    # when high test parallelism is used.
    NUM_PROCESSES: 16
    ICON4PY_NOX_UV_CUSTOM_SESSION_EXTRAS: "cuda12"


.test_distributed_aarch64:
  stage: test
  extends: [.test_template_distributed, .build_distributed_template]
  before_script:
    - cd /icon4py
    - ls -la $(pwd)
    - ls ${UV_PROJECT_ENVIRONMENT}/lib/python*/site-packages
    - echo "using MPICC ${MPICC}"
    - echo "using CC ${CC}"
  script:
    - . ${UV_PROJECT_ENVIRONMENT}/bin/activate && pytest -svv -k "mpi_tests" --datatest --with-mpi --backend=$BACKEND model/$COMPONENT
  parallel:
    matrix:
      - COMPONENT: [ atmosphere/diffusion, common] # [advection, diffusion, dycore, microphysics, common, driver]
        BACKEND: [ gtfn_cpu]
  rules:
    - when: on_success

test_model_distributed:
  extends: [.test_distributed_aarch64]

